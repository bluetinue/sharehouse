{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-EF3dqrX-qireo7dQzCEW7I7a7vEOW3K",
      "authorship_tag": "ABX9TyN+Bq3Hkt894EDA1bOXliv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluetinue/sharehouse/blob/main/CountryName.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 人名分类器\n"
      ],
      "metadata": {
        "id": "13O_r9yxyhxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 导包\n",
        "# prompt: 装载谷歌硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "# 显示所有变量\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# 导入torch工具\n",
        "import torch\n",
        "# 导入nn准备构建模型\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# 导入torch的数据源 数据迭代器工具包\n",
        "from  torch.utils.data import Dataset, DataLoader\n",
        "# 用于获得常见字母及字符规范化\n",
        "import string\n",
        "# 导入时间工具包\n",
        "import time\n",
        "# 引入制图工具包\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "BWAs7Zy5z-GR",
        "outputId": "5d8e0b41-21e2-41ac-8b5b-15a843aaa9c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "XAXMXZA1yGBZ"
      },
      "outputs": [],
      "source": [
        "# @title 读取数据\n",
        "data = pd.read_csv('/content/drive/MyDrive/NLP/data/name_classfication.txt',sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 数据预处理\n",
        "\n",
        "#去重后的词表\n",
        "all_letters = string.ascii_letters + \" ,.:'\"\n",
        "n_letters = len(all_letters)\n",
        "# 国家名 种类数\n",
        "categorys = ['Italian', 'English', 'Arabic', 'Spanish', 'Scottish', 'Irish', 'Chinese', 'Vietnamese', 'Japanese',\n",
        "             'French', 'Greek', 'Dutch', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Czech', 'German']\n",
        "# 国家名 个数\n",
        "categorynum = len(categorys)\n",
        "print('categorys--->', categorys)\n",
        "print('all_letters--->', all_letters)\n",
        "\n",
        "# 读取数据\n",
        "def read_data(path):\n",
        "  x,y = [],[]\n",
        "  with open(path,'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      line = line.strip().split('\\t')\n",
        "      x.append(line[0])\n",
        "      y.append(line[1])\n",
        "  return x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk3z1EYw5dv8",
        "outputId": "4c4c2052-b354-48d3-dba7-192d69c3f1ae",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorys---> ['Italian', 'English', 'Arabic', 'Spanish', 'Scottish', 'Irish', 'Chinese', 'Vietnamese', 'Japanese', 'French', 'Greek', 'Dutch', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Czech', 'German']\n",
            "all_letters---> abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ,.:'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 数据加载器\n",
        "#定义数据封装器类\n",
        "class NameclassifcationDataset(Dataset):\n",
        "    def __init__(self,x,y):\n",
        "      #将读取的数据封装起来\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.sample_len = len(x)\n",
        "\n",
        "    #调用len方法返回x的数量\n",
        "    def __len__(self):\n",
        "        return self.sample_len\n",
        "\n",
        "    #对进行切片操作时调用\n",
        "    def __getitem__(self, idx):\n",
        "      idx = min(max(0,idx),self.sample_len-1)\n",
        "\n",
        "      x = self.x[idx]\n",
        "      y = self.y[idx]\n",
        "\n",
        "      tensor_x = torch.zeros(len(x),n_letters)\n",
        "      for i,v in enumerate(x):\n",
        "        tensor_x[i][all_letters.find(v)] = 1\n",
        "\n",
        "      tensor_y = torch.tensor(categorys.index(y))\n",
        "\n",
        "      return tensor_x,tensor_y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YqtoXBdR6c2I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 迭代器\n",
        "def get_traindata():\n",
        "  path = \"/content/drive/MyDrive/NLP/data/name_classfication.txt\"\n",
        "  x,y = read_data(path)\n",
        "  nameclassdataset = NameclassifcationDataset(x,y)\n",
        "  train_loader = DataLoader(nameclassdataset,batch_size=1,shuffle=True)\n",
        "  for x,y in train_loader:\n",
        "    print(x.shape,y.shape)\n",
        "    break\n",
        "  return train_loader"
      ],
      "metadata": {
        "id": "0k24lZylSWGb",
        "cellView": "form"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 构建RNN\n",
        "# RNN类 实现思路分析：\n",
        "# 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)\n",
        "#    def __init__(self, input_size, hidden_size, output_size, num_layers=1)\n",
        "\n",
        "# 2 forward(input, hidden)函数\n",
        "#   让数据经过三个层 返回softmax结果和hn\n",
        "#   形状变化 [seqlen,1,57],[1,1,128]) -> [seqlen,1,128],[1,1,128]\n",
        "\n",
        "# 3 初始化隐藏层输入数据 inithidden()\n",
        "#   形状[self.num_layers, 1, self.hidden_size]\n",
        "class myRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super(myRNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    # #根据后边的损失函数如果是CrossEntropyLoss,就不需要softmax，是NLLLoss就需要加上softmax\n",
        "    # self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  #前向传播\n",
        "  def forward(self,input,hidden):\n",
        "    #input\n",
        "    input = input.unsqueeze(1)\n",
        "\n",
        "    rr,hn = self.rnn(input,hidden)\n",
        "    tmprr = rr[-1]\n",
        "    tmprr = self.out(tmprr)\n",
        "    return tmprr,hn\n",
        "\n",
        "  #初始化隐藏层输入数据\n",
        "  def inithidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)\n"
      ],
      "metadata": {
        "id": "RkmaUGxWGCEj",
        "cellView": "form"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 构建LSTM\n",
        "# LSTM类 实现思路分析：\n",
        "# 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)\n",
        "#    def __init__(self, input_size, hidden_size, output_size, num_layers=1)\n",
        "\n",
        "# 2 forward(input, hidden)函数\n",
        "#   让数据经过三个层 返回softmax结果和hn\n",
        "#   形状变化 [seqlen,1,57],[1,1,128]) -> [seqlen,1,128],[1,1,128]\n",
        "\n",
        "# 3 初始化隐藏层输入数据 inithidden()\n",
        "#   形状[self.num_layers, 1, self.hidden_size]\n",
        "class myLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    #根据后边的损失函数如果是CrossEntropyLoss,就不需要softmax，是NLLLoss就需要加上softmax\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  #前向传播\n",
        "  def forward(self,input,hidden,c):\n",
        "    #input\n",
        "    input = input.unsqueeze(1)\n",
        "\n",
        "    rr,(hn,cn) = self.lstm(input,(hidden,c))\n",
        "    tmprr = rr[-1]\n",
        "    tmprr = self.out(tmprr)\n",
        "    return self.softmax(tmprr),hn,cn\n",
        "\n",
        "  #初始化隐藏层输入数据\n",
        "  def inithidden(self):\n",
        "    hidden = c = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "    return hidden,c\n"
      ],
      "metadata": {
        "id": "vqEFe7hGz-NU",
        "cellView": "form"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 构建GRU\n",
        "# GRU类 实现思路分析：\n",
        "# 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)\n",
        "#    def __init__(self, input_size, hidden_size, output_size, num_layers=1)\n",
        "\n",
        "# 2 forward(input, hidden)函数\n",
        "#   让数据经过三个层 返回softmax结果和hn\n",
        "#   形状变化 [seqlen,1,57],[1,1,128]) -> [seqlen,1,128],[1,1,128]\n",
        "\n",
        "# 3 初始化隐藏层输入数据 inithidden()\n",
        "#   形状[self.num_layers, 1, self.hidden_size]\n",
        "class myGRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    #根据后边的损失函数如果是CrossEntropyLoss,就不需要softmax，是NLLLoss就需要加上softmax\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  #前向传播\n",
        "  def forward(self,input,hidden):\n",
        "    #input\n",
        "    input = input.unsqueeze(1)\n",
        "\n",
        "    rr,hn = self.rnn(input,hidden)\n",
        "    tmprr = rr[-1]\n",
        "    tmprr = self.out(tmprr)\n",
        "    return self.softmax(tmprr),hn\n",
        "\n",
        "  #初始化隐藏层输入数据\n",
        "  def inithidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wqHLBBm0YWjq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 思路分析\n",
        "# 从文件获取数据、实例化数据源对象nameclassdataset 数据迭代器对象mydataloader\n",
        "# 实例化模型对象my_rnn 损失函数对象mycrossentropyloss=nn.NLLLoss() 优化器对象myadam\n",
        "# 定义模型训练的参数\n",
        "#       starttime total_iter_num total_loss  total_loss_list total_acc_num  total_acc_list\n",
        "# 外层for循环 控制轮数 for epoch_idx in range(epochs)\n",
        "# 内层for循环 控制迭代次数 for i, (x, y) in enumerate(mydataloader)\n",
        "    # 给模型喂数据   # 计算损失  # 梯度清零 # 反向传播  # 梯度更新\n",
        "    # 计算辅助信息   # 累加总损失和准确数 每100次训练计算一个总体平均损失 总体平均准确率 每2000次训练 打印日志\n",
        "    # 其他          # 预测对错 i_predit_tag = (1 if torch.argmax(output).item() == y.item() else 0)\n",
        "\n",
        "# 模型保存\n",
        "    # torch.save(my_rnn.state_dict(), './my_rnn_model_%d.bin' % (epoch_idx + 1))\n",
        "# 返回 平均损失列表total_loss_list, 时间total_time, 平均准确total_acc_list"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BsS0U3uyzeJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查是否有可用的CUDA设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "epochs = 1\n",
        "lr = 1e-3\n",
        "def train_rnn():\n",
        "  #实例化dataloader\n",
        "  rnn_dataloader = get_traindata()\n",
        "  #实例化模型\n",
        "  input_size = all_letters\n",
        "  hidden_size = 200\n",
        "  output_size = categorynum\n",
        "  my_rnn = myRNN(input_size=n_letters,\n",
        "                 hidden_size=hidden_size,\n",
        "                 output_size=categorynum).to(device=device)\n",
        "\n",
        "  #损失函数和优化器\n",
        "  myloss = nn.NLLLoss()\n",
        "  myoptimizer = optim.Adam(my_rnn.parameters(), lr=lr)\n",
        "\n",
        "  #训练日志参数\n",
        "  starttime = time.time()\n",
        "  total_iter_num = 0 #已经训练的样本数\n",
        "  total_loss = 0  #已经训练的损失和\n",
        "  total_loss_list = [] #每批样本求一次平均损失\n",
        "  total_acc_num = 0 #训练样本准确总数\n",
        "  total_acc_list = [] #平均准确率列表\n",
        "\n",
        "  #开始训练\n",
        "\n",
        "\n",
        "  #前向传播\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGVWDJIuDH03",
        "outputId": "a36f1a25-3506-4398-c6ac-9c20950a49c4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "sI9fr8F1D9KE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RNN训练\n",
        "# 检查是否有可用的CUDA设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "lr = 1e-4\n",
        "epochs = 10\n",
        "path = \"/content/drive/MyDrive/NLP/data/name_classfication.txt\"\n",
        "x,y = read_data(path)\n",
        "def train_rnn(x,y):\n",
        "  #实例化dataloader\n",
        "\n",
        "  input_size = all_letters\n",
        "  hidden_size = 200\n",
        "  output_size = categorynum\n",
        "  #实例化模型\n",
        "  my_rnn = myRNN(input_size=n_letters,\n",
        "                 hidden_size=hidden_size,\n",
        "                 output_size=categorynum).to(device) # 将模型移动到GPU\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(my_rnn.parameters(), lr=lr)\n",
        "\n",
        "  starttime = time.time()\n",
        "  total_iter_num = 0 #已经训练的样本数\n",
        "  total_loss = 0  #已经训练的损失和\n",
        "  total_loss_list = [] #每批样本求一次平均损失\n",
        "  total_acc_num = 0 #训练样本准确总数\n",
        "  total_acc_list = [] #平均准确率列表\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    namedataloader = get_traindata()\n",
        "    for i,(x,y) in enumerate(tqdm(namedataloader)):\n",
        "      x,y = x.to(device), y.to(device) # 将数据移动到GPU\n",
        "      hidden = my_rnn.inithidden().to(device) # 将隐藏层初始化数据移动到GPU\n",
        "      output,hidden = my_rnn(x[0],hidden)\n",
        "      loss = loss_fn(output,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #计算损失\n",
        "      total_iter_num = total_iter_num + 1\n",
        "      total_loss = total_loss + loss.item()\n",
        "      #计算准确率\n",
        "      i_predit_tag = (1 if torch.argmax(output).item() == y.item() else 0)\n",
        "      total_acc_num = total_acc_num + i_predit_tag\n",
        "      #每100次训练计算一次平均损失\n",
        "      if (total_iter_num % 100 == 0):\n",
        "        tmploss = total_loss / total_iter_num\n",
        "        total_loss_list.append(tmploss)\n",
        "\n",
        "        tmpacc = total_acc_num / total_iter_num\n",
        "        total_acc_list.append(tmpacc)\n",
        "      #每1000次训练打印日志\n",
        "      if (total_iter_num % 1000 == 0):\n",
        "        total_time = time.time() - starttime\n",
        "        print(f'轮次{epoch+1},损失{tmploss:.6f},\\\n",
        "        时间{time.time()-starttime:.6f},准确率{tmpacc:.6f}')\n",
        "    #保存训练好的模型\n",
        "    torch.save(my_rnn.state_dict(), '/content/drive/MyDrive/NLP/model/my_rnn_model.bin')\n",
        "  #计算总时间\n",
        "  total_time = int(time.time() - starttime)\n",
        "\n",
        "  return total_loss_list, total_time, total_acc_list\n",
        "\n",
        "total_loss_list, total_time, total_acc_list = train_rnn(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0MG_fNTz-Pz",
        "outputId": "2b6a3e0f-f66f-4de7-fecd-c4b5b9683833",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "torch.Size([1, 4, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1041/20074 [00:02<00:36, 514.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.872930,        时间2.013593,准确率0.460000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 2055/20074 [00:04<00:47, 381.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.760124,        时间4.461432,准确率0.494000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 3093/20074 [00:06<00:33, 509.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.693796,        时间6.610350,准确率0.513000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 4086/20074 [00:08<00:32, 498.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.659009,        时间8.596298,准确率0.519750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 5091/20074 [00:10<00:30, 484.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.622692,        时间10.546066,准确率0.530400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 6093/20074 [00:12<00:27, 507.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.598071,        时间12.545342,准确率0.538333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 7073/20074 [00:14<00:25, 504.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.566969,        时间14.559256,准确率0.547143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 8070/20074 [00:17<00:29, 409.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.538700,        时间16.894881,准确率0.553625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 9052/20074 [00:19<00:22, 498.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.515959,        时间19.157108,准确率0.559889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 10089/20074 [00:21<00:19, 502.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.489366,        时间21.153398,准确率0.566100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 11045/20074 [00:23<00:22, 396.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.462809,        时间23.593786,准确率0.574545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 12076/20074 [00:26<00:16, 472.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.443070,        时间25.888770,准确率0.581083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 13049/20074 [00:27<00:13, 509.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.426597,        时间27.897486,准确率0.585308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 14068/20074 [00:30<00:14, 413.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.409323,        时间30.336569,准确率0.590429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 15066/20074 [00:32<00:10, 471.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.393603,        时间32.575844,准确率0.595467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 16085/20074 [00:34<00:08, 476.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.377904,        时间34.607134,准确率0.600250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 17064/20074 [00:36<00:06, 494.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.363398,        时间36.618461,准确率0.604353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 18092/20074 [00:38<00:03, 501.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.348329,        时间38.634213,准确率0.609167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 19070/20074 [00:40<00:01, 510.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.336269,        时间40.646587,准确率0.612789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:43<00:00, 465.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次1,损失1.323585,        时间42.999061,准确率0.617350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 927/20074 [00:02<00:44, 430.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.311121,        时间45.897936,准确率0.621762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 1982/20074 [00:05<00:35, 514.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.297016,        时间48.116082,准确率0.625773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 3023/20074 [00:07<00:32, 516.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.288558,        时间50.117362,准确率0.628435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 4018/20074 [00:09<00:31, 514.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.277481,        时间52.100516,准确率0.631583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 5007/20074 [00:11<00:31, 476.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.271450,        时间54.100135,准确率0.633440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 5976/20074 [00:13<00:37, 378.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.261633,        时间56.536513,准确率0.635769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 6989/20074 [00:15<00:26, 491.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.252351,        时间58.733479,准确率0.638667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 7899/20074 [00:17<00:23, 525.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.243685,        时间60.657570,准确率0.641036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 8980/20074 [00:19<00:22, 485.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.235492,        时间62.729982,准确率0.643103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 10014/20074 [00:21<00:20, 492.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.226836,        时间64.739981,准确率0.645600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 10999/20074 [00:23<00:17, 511.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.218153,        时间66.718930,准确率0.648000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 11986/20074 [00:26<00:19, 422.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.211945,        时间69.100321,准确率0.649875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 12972/20074 [00:28<00:14, 491.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.203953,        时间71.337554,准确率0.652727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 14015/20074 [00:30<00:12, 482.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.197580,        时间73.354892,准确率0.654529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 15017/20074 [00:32<00:10, 496.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.190081,        时间75.303507,准确率0.656514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 16013/20074 [00:34<00:08, 499.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.182704,        时间77.301817,准确率0.658167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 17014/20074 [00:36<00:05, 517.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.178043,        时间79.281027,准确率0.659703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 17992/20074 [00:38<00:05, 381.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.171416,        时间81.595399,准确率0.661895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 18981/20074 [00:40<00:02, 490.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.164397,        时间83.964445,准确率0.664026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 20006/20074 [00:42<00:00, 488.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次2,损失1.159235,        时间86.017018,准确率0.665675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:43<00:00, 465.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 957/20074 [00:01<00:36, 526.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.152369,        时间88.000182,准确率0.667780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 1945/20074 [00:03<00:35, 503.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.148443,        时间89.992093,准确率0.668786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 2934/20074 [00:05<00:34, 498.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.143920,        时间91.977495,准确率0.669953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 3906/20074 [00:07<00:38, 420.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.138163,        时间94.157017,准确率0.671273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 4948/20074 [00:10<00:31, 485.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.133371,        时间96.622177,准确率0.672689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 5943/20074 [00:12<00:27, 505.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.127063,        时间98.618385,准确率0.674283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 6934/20074 [00:14<00:26, 499.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.121728,        时间100.611325,准确率0.675766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 7919/20074 [00:16<00:25, 483.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.116821,        时间102.599714,准确率0.676958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 8921/20074 [00:18<00:23, 478.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.112533,        时间104.586511,准确率0.678102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 9896/20074 [00:20<00:25, 403.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.107104,        时间106.670394,准确率0.679680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 10922/20074 [00:23<00:21, 423.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.101546,        时间109.211471,准确率0.681255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 11914/20074 [00:24<00:15, 515.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.097086,        时间111.192368,准确率0.682481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 12951/20074 [00:27<00:14, 503.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.092701,        时间113.190542,准确率0.683377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 13939/20074 [00:29<00:11, 516.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.089092,        时间115.175938,准确率0.684204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 14952/20074 [00:30<00:09, 526.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.084914,        时间117.138846,准确率0.685345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 15896/20074 [00:32<00:07, 526.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.081573,        时间119.108871,准确率0.686232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 16904/20074 [00:35<00:07, 400.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.078133,        时间121.583974,准确率0.687140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 17914/20074 [00:37<00:04, 490.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.075953,        时间123.779767,准确率0.687810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 18956/20074 [00:39<00:02, 499.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.071928,        时间125.774611,准确率0.689000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 19904/20074 [00:41<00:00, 500.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次3,损失1.067793,        时间127.732303,准确率0.690250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:41<00:00, 479.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 833/20074 [00:01<00:39, 492.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.064406,        时间129.741620,准确率0.691082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 1884/20074 [00:03<00:35, 508.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.061143,        时间131.710029,准确率0.691887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 2827/20074 [00:06<00:40, 423.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.057767,        时间134.082291,准确率0.692683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 3858/20074 [00:08<00:33, 488.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.053872,        时间136.342356,准确率0.693641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 4833/20074 [00:10<00:30, 503.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.049624,        时间138.353623,准确率0.694862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 5868/20074 [00:12<00:29, 487.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.045774,        时间140.378351,准确率0.695818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 6817/20074 [00:14<00:26, 498.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.041495,        时间142.339594,准确率0.696970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 7842/20074 [00:16<00:25, 481.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.038809,        时间144.395880,准确率0.697779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 8851/20074 [00:18<00:27, 407.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.035312,        时间146.774973,准确率0.698609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 9880/20074 [00:21<00:19, 522.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.032362,        时间149.049835,准确率0.699386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 10865/20074 [00:23<00:18, 509.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.029501,        时间151.062725,准确率0.700211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 11843/20074 [00:25<00:16, 492.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.026759,        时间153.077667,准确率0.701042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 12840/20074 [00:27<00:14, 508.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.023116,        时间155.058720,准确率0.702123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 13841/20074 [00:28<00:12, 516.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.020348,        时间157.009512,准确率0.702824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 14825/20074 [00:31<00:12, 405.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.017916,        时间159.157883,准确率0.703533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 15852/20074 [00:33<00:08, 496.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.015043,        时间161.605567,准确率0.704500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 16831/20074 [00:35<00:06, 482.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.013636,        时间163.631108,准确率0.704909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 17869/20074 [00:37<00:04, 490.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.011531,        时间165.621040,准确率0.705474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 18857/20074 [00:39<00:02, 506.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.008080,        时间167.609480,准确率0.706291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 19839/20074 [00:41<00:00, 486.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次4,损失1.006207,        时间169.648476,准确率0.706738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:42<00:00, 477.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 781/20074 [00:01<00:46, 411.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失1.004156,        时间171.824976,准确率0.707333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 1784/20074 [00:04<00:39, 468.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失1.001749,        时间174.289455,准确率0.707902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 2756/20074 [00:06<00:33, 512.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.999754,        时间176.305507,准确率0.708482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 3772/20074 [00:08<00:34, 468.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.997108,        时间178.369044,准确率0.708976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 4767/20074 [00:10<00:29, 523.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.994492,        时间180.340864,准确率0.709729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 5756/20074 [00:12<00:28, 510.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.991702,        时间182.344787,准确率0.710419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 6743/20074 [00:14<00:31, 418.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.989554,        时间184.372069,准确率0.710966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 7774/20074 [00:16<00:31, 390.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.987343,        时间186.840599,准确率0.711545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 8770/20074 [00:18<00:23, 487.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.985278,        时间188.967845,准确率0.712056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 9809/20074 [00:20<00:19, 522.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.982354,        时间190.966748,准确率0.712767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 10801/20074 [00:22<00:17, 516.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.979839,        时间192.957655,准确率0.713495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 11778/20074 [00:24<00:16, 516.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.977836,        时间194.973454,准确率0.713957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 12765/20074 [00:26<00:14, 502.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.976042,        时间196.968220,准确率0.714538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 13779/20074 [00:29<00:16, 389.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.973917,        时间199.387116,准确率0.715223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 14797/20074 [00:31<00:10, 516.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.971799,        时间201.587276,准确率0.715895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 15784/20074 [00:33<00:08, 480.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.970196,        时间203.603069,准确率0.716219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 16777/20074 [00:35<00:06, 491.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.967993,        时间205.583456,准确率0.716680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 17801/20074 [00:37<00:04, 498.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.965932,        时间207.625700,准确率0.717194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 18777/20074 [00:39<00:02, 502.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.964422,        时间209.642220,准确率0.717717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 19764/20074 [00:42<00:00, 382.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次5,损失0.961981,        时间212.152368,准确率0.718420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:42<00:00, 468.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 688/20074 [00:01<00:54, 358.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.960321,        时间214.985561,准确率0.718723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 1716/20074 [00:04<00:37, 484.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.957822,        时间217.223765,准确率0.719441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 2716/20074 [00:06<00:33, 516.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.956305,        时间219.221466,准确率0.719786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 3710/20074 [00:08<00:32, 506.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.953983,        时间221.221282,准确率0.720404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 4718/20074 [00:10<00:32, 471.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.952457,        时间223.175508,准确率0.720705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 5688/20074 [00:12<00:32, 439.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.950663,        时间225.254160,准确率0.721113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 6700/20074 [00:14<00:37, 357.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.948595,        时间227.792034,准确率0.721636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 7714/20074 [00:16<00:24, 498.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.946766,        时间229.864534,准确率0.722009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 8698/20074 [00:18<00:22, 507.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.944669,        时间231.866143,准确率0.722550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 9727/20074 [00:20<00:20, 497.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.942675,        时间233.881097,准确率0.723000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 10715/20074 [00:22<00:18, 504.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.941165,        时间235.874617,准确率0.723297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 11693/20074 [00:24<00:16, 509.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.939466,        时间237.894460,准确率0.723723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 12653/20074 [00:27<00:18, 395.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.937869,        时间240.388319,准确率0.724124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 13723/20074 [00:29<00:12, 489.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.936348,        时间242.582245,准确率0.724474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 14695/20074 [00:31<00:10, 494.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.934849,        时间244.623707,准确率0.724878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 15689/20074 [00:33<00:09, 471.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.933159,        时间246.605658,准确率0.725345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 16681/20074 [00:35<00:06, 497.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.931674,        时间248.583671,准确率0.725744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 17678/20074 [00:37<00:04, 510.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.930145,        时间250.573671,准确率0.726161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 18699/20074 [00:39<00:03, 413.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.928299,        时间252.990288,准确率0.726655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 19722/20074 [00:42<00:00, 503.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次6,损失0.926894,        时间255.254635,准确率0.726967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20074/20074 [00:42<00:00, 466.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 57]) torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 625/20074 [00:01<00:39, 486.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.925827,        时间257.266298,准确率0.727223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 1609/20074 [00:03<00:36, 502.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.923801,        时间259.274571,准确率0.727820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 2634/20074 [00:05<00:34, 500.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.922117,        时间261.297391,准确率0.728195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 3635/20074 [00:07<00:34, 476.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.920626,        时间263.251465,准确率0.728629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 4616/20074 [00:09<00:37, 414.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.919334,        时间265.548135,准确率0.728976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 5630/20074 [00:11<00:29, 496.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.918177,        时间267.973057,准确率0.729230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 6622/20074 [00:13<00:26, 509.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.916483,        时间269.975018,准确率0.729559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 7613/20074 [00:15<00:24, 517.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.915394,        时间271.961864,准确率0.729852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 8657/20074 [00:17<00:21, 520.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.913922,        时间273.960064,准确率0.730217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 9659/20074 [00:19<00:20, 511.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.912744,        时间275.914955,准确率0.730592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 10613/20074 [00:22<00:23, 403.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.911122,        时间278.101777,准确率0.730939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 11617/20074 [00:24<00:17, 470.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.909574,        时间280.573284,准确率0.731364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 12607/20074 [00:26<00:14, 500.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.908319,        时间282.552270,准确率0.731669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 13640/20074 [00:28<00:12, 510.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.906635,        时间284.566494,准确率0.732052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 14627/20074 [00:30<00:11, 478.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "轮次7,损失0.905554,        时间286.563240,准确率0.732304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 15201/20074 [00:31<00:09, 514.09it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 构建LSTM\n",
        "# LSTM类 实现思路分析：\n",
        "# 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)\n",
        "#    def __init__(self, input_size, hidden_size, output_size, num_layers=1)\n",
        "\n",
        "# 2 forward(input, hidden)函数\n",
        "#   让数据经过三个层 返回softmax结果和hn\n",
        "#   形状变化 [seqlen,1,57],[1,1,128]) -> [seqlen,1,128],[1,1,128]\n",
        "\n",
        "# 3 初始化隐藏层输入数据 inithidden()\n",
        "#   形状[self.num_layers, 1, self.hidden_size]\n",
        "class myLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    #根据后边的损失函数如果是CrossEntropyLoss,就不需要softmax，是NLLLoss就需要加上softmax\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  #前向传播\n",
        "  def forward(self,input,hidden,c):\n",
        "    #input\n",
        "    input = input.unsqueeze(1)\n",
        "\n",
        "    rr,(hn,cn) = self.lstm(input,(hidden,c))\n",
        "    tmprr = rr[-1]\n",
        "    tmprr = self.out(tmprr)\n",
        "    return self.softmax(tmprr),hn,cn\n",
        "\n",
        "  #初始化隐藏层输入数据\n",
        "  def inithidden(self):\n",
        "    hidden = c = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "    return hidden,c\n",
        "\n",
        "#@title LSTM训练\n",
        "lr = 1e-3\n",
        "epochs = 10\n",
        "path = \"/content/drive/MyDrive/NLP/data/name_classfication.txt\"\n",
        "x,y = read_data(path)\n",
        "def train_lstm(x,y):\n",
        "  # 检查是否有可用的CUDA设备\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  #实例化dataloader\n",
        "  namedataloader = get_traindata()\n",
        "  input_size = all_letters\n",
        "  hidden_size = 200\n",
        "  output_size = categorynum\n",
        "  #实例化模型\n",
        "  my_lstm = myLSTM(input_size=n_letters,\n",
        "                 hidden_size=hidden_size,\n",
        "                 output_size=categorynum).to(device) # 将模型移动到GPU\n",
        "\n",
        "  loss_fn = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(my_lstm.parameters(), lr=lr)\n",
        "\n",
        "  starttime = time.time()\n",
        "  total_iter_num = 0 #已经训练的样本数\n",
        "  total_loss = 0  #已经训练的损失和\n",
        "  total_loss_list = [] #每批样本求一次平均损失\n",
        "  total_acc_num = 0 #训练样本准确总数\n",
        "  total_acc_list = [] #平均准确率列表\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for i,(x,y) in enumerate(namedataloader):\n",
        "      x,y = x.to(device), y.to(device) # 将数据移动到GPU\n",
        "      hidden,c = [h.to(device) for h in my_lstm.inithidden()] # 将隐藏层初始化数据移动到GPU\n",
        "      output,hidden,c = my_lstm(x[0],hidden,c)\n",
        "\n",
        "      loss = loss_fn(output,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #计算损失\n",
        "      total_iter_num = total_iter_num + 1\n",
        "      total_loss = total_loss + loss.item()\n",
        "      #计算准确率\n",
        "      i_predit_tag = (1 if torch.argmax(output).item() == y.item() else 0)\n",
        "      total_acc_num = total_acc_num + i_predit_tag\n",
        "      #每100次训练计算一次平均损失\n",
        "      if (total_iter_num % 100 == 0):\n",
        "        tmploss = total_loss / total_iter_num\n",
        "        total_loss_list.append(tmploss)\n",
        "\n",
        "        tmpacc = total_acc_num / total_iter_num\n",
        "        total_acc_list.append(tmpacc)\n",
        "      #每1000次训练打印日志\n",
        "      if (total_iter_num % 1000 == 0):\n",
        "        total_time = time.time() - starttime\n",
        "        print(f'轮次{epoch+1},损失{tmploss},\\\n",
        "        时间{time.time()-starttime},准确率{tmpacc}')\n",
        "  #计算总时间\n",
        "  total_time = int(time.time() - starttime)\n",
        "  #保存训练好的模型\n",
        "  torch.save(my_lstm.state_dict(), '/content/drive/MyDrive/NLP/model/my_lstm_model.bin')\n",
        "  return total_lloss_list, total_ltime, total_lacc_list\n",
        "\n",
        "total_lloss_list, total_ltime, total_lacc_list = train_lstm(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRmxp4UvyzJZ",
        "outputId": "31651d64-0942-4633-c770-1bf39cd578d5",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 57]) torch.Size([1])\n",
            "轮次1,损失1.7274325644169002,        时间4.453881025314331,准确率0.491\n",
            "轮次1,损失1.5818474416137325,        时间8.699905157089233,准确率0.537\n",
            "轮次1,损失1.4878163814740353,        时间14.078070402145386,准确率0.567\n",
            "轮次1,损失1.4156519952359194,        时间18.525463819503784,准确率0.587\n",
            "轮次1,损失1.353881533367309,        时间23.819997310638428,准确率0.6076\n",
            "轮次1,损失1.3033076276193194,        时间28.59471893310547,准确率0.6203333333333333\n",
            "轮次1,损失1.2645274292429407,        时间32.91413187980652,准确率0.6321428571428571\n",
            "轮次1,损失1.2298001573693838,        时间38.90065884590149,准确率0.640375\n",
            "轮次1,损失1.2093263277982906,        时间42.914738178253174,准确率0.6453333333333333\n",
            "轮次1,损失1.1819309188892053,        时间48.39391326904297,准确率0.6517\n",
            "轮次1,损失1.1564070404489362,        时间52.703277349472046,准确率0.6601818181818182\n",
            "轮次1,损失1.131950978658327,        时间56.90431785583496,准确率0.66575\n",
            "轮次1,损失1.113162177726303,        时间62.199392557144165,准确率0.6721538461538461\n",
            "轮次1,损失1.0939554187730358,        时间66.326988697052,准确率0.6763571428571429\n",
            "轮次1,损失1.0783398531870798,        时间69.9215795993805,准确率0.6804\n",
            "轮次1,损失1.0646748012796177,        时间74.80904603004456,准确率0.684125\n",
            "轮次1,损失1.0496888565781382,        时间79.20469260215759,准确率0.688\n",
            "轮次1,损失1.0356245644317075,        时间84.20687818527222,准确率0.6916111111111111\n",
            "轮次1,损失1.0207046511327997,        时间88.95944619178772,准确率0.6963157894736842\n",
            "轮次1,损失1.0058954254668993,        时间92.74087285995483,准确率0.70085\n",
            "轮次2,损失0.9938519298189297,        时间97.41742610931396,准确率0.7036190476190476\n",
            "轮次2,损失0.9781310656288568,        时间102.26080918312073,准确率0.7080454545454545\n",
            "轮次2,损失0.9662440366655248,        时间106.68168997764587,准确率0.7108695652173913\n",
            "轮次2,损失0.9550732652873701,        时间111.95535635948181,准确率0.714625\n",
            "轮次2,损失0.9447654957132032,        时间115.88959097862244,准确率0.71816\n",
            "轮次2,损失0.933463971250219,        时间119.77001309394836,准确率0.7211153846153846\n",
            "轮次2,损失0.9235034279987877,        时间124.52025961875916,准确率0.7242222222222222\n",
            "轮次2,损失0.915493134706286,        时间128.46908521652222,准确率0.7263571428571428\n",
            "轮次2,损失0.9060782281045824,        时间132.30229687690735,准确率0.7290344827586207\n",
            "轮次2,损失0.8965760671730851,        时间137.24297904968262,准确率0.7316666666666667\n",
            "轮次2,损失0.8892125861815201,        时间141.5821669101715,准确率0.7336129032258064\n",
            "轮次2,损失0.880549747355491,        时间145.47556114196777,准确率0.73615625\n",
            "轮次2,损失0.8723851183102533,        时间150.40962743759155,准确率0.7383939393939394\n",
            "轮次2,损失0.8642937407950155,        时间154.5692982673645,准确率0.7408823529411764\n",
            "轮次2,损失0.8572344754602299,        时间159.1562626361847,准确率0.7428285714285714\n",
            "轮次2,损失0.8498395571898097,        时间164.01809787750244,准确率0.7450833333333333\n",
            "轮次2,损失0.8436293064776109,        时间168.23695135116577,准确率0.7468648648648649\n",
            "轮次2,损失0.8383510961355863,        时间173.02874875068665,准确率0.7483947368421052\n",
            "轮次2,损失0.8315065735792089,        时间177.36594986915588,准确率0.7501025641025642\n",
            "轮次2,损失0.8258714389080818,        时间182.05032658576965,准确率0.7516\n",
            "轮次3,损失0.8193902660748706,        时间187.24331307411194,准确率0.7533170731707317\n",
            "轮次3,损失0.8126474417106724,        时间191.99059081077576,准确率0.7548333333333334\n",
            "轮次3,损失0.8070719023746119,        时间197.37363982200623,准确率0.7565348837209303\n",
            "轮次3,损失0.8004567428614008,        时间201.4581949710846,准确率0.7583409090909091\n",
            "轮次3,损失0.7943096210438683,        时间205.82184529304504,准确率0.7601555555555556\n",
            "轮次3,损失0.7890642906182962,        时间210.47696948051453,准确率0.7617391304347826\n",
            "轮次3,损失0.7825678701258008,        时间215.00741457939148,准确率0.7636170212765957\n",
            "轮次3,损失0.7767221576912517,        时间219.41998744010925,准确率0.7650625\n",
            "轮次3,损失0.7719517365074787,        时间224.5140278339386,准确率0.7662448979591837\n",
            "轮次3,损失0.7666101468703009,        时间228.59543013572693,准确率0.7678\n",
            "轮次3,损失0.7612089920692698,        时间232.7033407688141,准确率0.769235294117647\n",
            "轮次3,损失0.7555206705626413,        时间237.5624611377716,准确率0.7708653846153846\n",
            "轮次3,损失0.7504508069402335,        时间241.4027554988861,准确率0.772245283018868\n",
            "轮次3,损失0.7460197807141098,        时间246.12878561019897,准确率0.7734814814814814\n",
            "轮次3,损失0.7414823781428334,        时间250.1642575263977,准确率0.7746363636363637\n",
            "轮次3,损失0.7370671303466809,        时间254.0708224773407,准确率0.7759107142857142\n",
            "轮次3,损失0.7327673796323815,        时间258.7263741493225,准确率0.7771929824561403\n",
            "轮次3,损失0.7293227033961809,        时间262.41513895988464,准确率0.7779137931034483\n",
            "轮次3,损失0.7262359927937453,        时间266.1897087097168,准确率0.7788983050847458\n",
            "轮次3,损失0.7224069316214526,        时间269.98390674591064,准确率0.7799333333333334\n",
            "轮次4,损失0.7174908212236015,        时间273.8162467479706,准确率0.7812459016393443\n",
            "轮次4,损失0.7122890441933742,        时间277.7887740135193,准确率0.7826774193548387\n",
            "轮次4,损失0.7071771077783386,        时间282.92072439193726,准确率0.7840952380952381\n",
            "轮次4,损失0.7020342309268398,        时间288.2864897251129,准确率0.7855\n",
            "轮次4,损失0.6977743285337576,        时间292.7831280231476,准确率0.786676923076923\n",
            "轮次4,损失0.6934203580650047,        时间297.99989461898804,准确率0.787969696969697\n",
            "轮次4,损失0.6897576787091929,        时间301.73756432533264,准确率0.7890298507462686\n",
            "轮次4,损失0.6856010249359027,        时间306.4008939266205,准确率0.7903088235294118\n",
            "轮次4,损失0.682158716917316,        时间311.43037700653076,准确率0.7913478260869565\n",
            "轮次4,损失0.6788149036190432,        时间315.9894940853119,准确率0.7922285714285714\n",
            "轮次4,损失0.6756937069134803,        时间320.598224401474,准确率0.7930704225352113\n",
            "轮次4,损失0.672304103463762,        时间324.18789935112,准确率0.7939861111111111\n",
            "轮次4,损失0.6689620743653991,        时间328.5870888233185,准确率0.7949041095890411\n",
            "轮次4,损失0.6656138548360458,        时间333.8662009239197,准确率0.7957837837837838\n",
            "轮次4,损失0.6624554126380279,        时间337.6170663833618,准确率0.7966133333333333\n",
            "轮次4,损失0.6593760647481709,        时间342.11136746406555,准确率0.7974868421052631\n",
            "轮次4,损失0.6562696499327851,        时间347.4090497493744,准确率0.7983506493506494\n",
            "轮次4,损失0.6541529760050739,        时间351.40745091438293,准确率0.7988846153846154\n",
            "轮次4,损失0.6508213773221453,        时间355.6260151863098,准确率0.7997594936708861\n",
            "轮次4,损失0.648217047982944,        时间359.93551087379456,准确率0.800525\n",
            "轮次5,损失0.6447099711947801,        时间363.7916715145111,准确率0.8015432098765433\n",
            "轮次5,损失0.6408620035009225,        时间368.104101896286,准确率0.8025853658536586\n",
            "轮次5,损失0.6373009342637538,        时间372.6779143810272,准确率0.8035903614457831\n",
            "轮次5,损失0.6335555775972784,        时间376.2872099876404,准确率0.8047380952380953\n",
            "轮次5,损失0.6298597273598687,        时间380.2301163673401,准确率0.8057176470588235\n",
            "轮次5,损失0.6268851668788037,        时间384.4427363872528,准确率0.8065116279069767\n",
            "轮次5,损失0.6234093854510866,        时间388.41324615478516,准确率0.8075172413793104\n",
            "轮次5,损失0.6205390863056794,        时间392.27771854400635,准确率0.8083181818181818\n",
            "轮次5,损失0.6171599678067509,        时间396.60729002952576,准确率0.8093258426966292\n",
            "轮次5,损失0.6143438159276032,        时间400.1936447620392,准确率0.8101\n",
            "轮次5,损失0.6118206037347986,        时间403.9594235420227,准确率0.8109340659340659\n",
            "轮次5,损失0.6091595630240886,        时间408.69032192230225,准确率0.8116847826086957\n",
            "轮次5,损失0.6066510903252961,        时间412.42385149002075,准确率0.8124731182795699\n",
            "轮次5,损失0.6041941163406749,        时间416.19143414497375,准确率0.8132127659574468\n",
            "轮次5,损失0.6015893265780068,        时间420.9111087322235,准确率0.8139578947368421\n",
            "轮次5,损失0.5990527584575387,        时间424.85978841781616,准确率0.81459375\n",
            "轮次5,损失0.5964070564312668,        时间428.4460117816925,准确率0.8153298969072165\n",
            "轮次5,损失0.594360778158297,        时间433.24365973472595,准确率0.8157857142857143\n",
            "轮次5,损失0.5917461049137299,        时间437.66067457199097,准确率0.8166060606060606\n",
            "轮次5,损失0.5896064258362373,        时间442.201553106308,准确率0.81724\n",
            "轮次6,损失0.586488931411978,        时间446.6802101135254,准确率0.8181782178217821\n",
            "轮次6,损失0.5829259984017701,        时间450.2626554965973,准确率0.8191764705882353\n",
            "轮次6,损失0.5793922248864504,        时间454.4890651702881,准确率0.8202718446601942\n",
            "轮次6,损失0.5765733317679042,        时间458.8152675628662,准确率0.8210192307692308\n",
            "轮次6,损失0.5736276620279137,        时间462.67027616500854,准确率0.8219238095238095\n",
            "轮次6,损失0.5712563787283353,        时间467.53621792793274,准确率0.8226320754716981\n",
            "轮次6,损失0.568351135781584,        时间472.4588668346405,准确率0.8235233644859813\n",
            "轮次6,损失0.5657146118773397,        时间477.1177484989166,准确率0.8242962962962963\n",
            "轮次6,损失0.5630371513047017,        时间481.97049617767334,准确率0.8250642201834862\n",
            "轮次6,损失0.5604483864137868,        时间485.97002363204956,准确率0.8258\n",
            "轮次6,损失0.558280192067198,        时间489.9315207004547,准确率0.8264414414414415\n",
            "轮次6,损失0.5562049348634894,        时间494.60806703567505,准确率0.8270089285714286\n",
            "轮次6,损失0.553961449829772,        时间498.5870246887207,准确率0.8276194690265487\n",
            "轮次6,损失0.5516758973862416,        时间503.2830591201782,准确率0.8282719298245614\n",
            "轮次6,损失0.5495081416535015,        时间508.11760997772217,准确率0.8289130434782609\n",
            "轮次6,损失0.5474862158897202,        时间512.5992045402527,准确率0.8295\n",
            "轮次6,损失0.5456496225950686,        时间517.1975178718567,准确率0.830017094017094\n",
            "轮次6,损失0.5438336921687351,        时间521.0043873786926,准确率0.8304830508474577\n",
            "轮次6,损失0.5417560269439605,        时间524.9948356151581,准确率0.8310672268907563\n",
            "轮次6,损失0.539634378576414,        时间529.8920550346375,准确率0.831625\n",
            "轮次7,损失0.5369763835660483,        时间533.9991841316223,准确率0.8324793388429752\n",
            "轮次7,损失0.5341688369083434,        时间538.502810716629,准确率0.8333688524590164\n",
            "轮次7,损失0.5316818273866111,        时间543.1040351390839,准确率0.834130081300813\n",
            "轮次7,损失0.5292708949370745,        时间547.3931570053101,准确率0.8348709677419355\n",
            "轮次7,损失0.526810232156718,        时间551.7712156772614,准确率0.835624\n",
            "轮次7,损失0.5246052750599477,        时间556.27015376091,准确率0.8363174603174603\n",
            "轮次7,损失0.5222081329954644,        时间560.6472454071045,准确率0.837007874015748\n",
            "轮次7,损失0.5197955798134364,        时间565.1234087944031,准确率0.8377734375\n",
            "轮次7,损失0.5177860750096456,        时间569.4225089550018,准确率0.8383720930232558\n",
            "轮次7,损失0.5156739286844287,        时间573.5519559383392,准确率0.8389846153846154\n",
            "轮次7,损失0.5137236654195173,        时间578.1432023048401,准确率0.8395725190839695\n",
            "轮次7,损失0.5121833997400358,        时间581.8464014530182,准确率0.8400454545454545\n",
            "轮次7,损失0.51040142320005,        时间585.9525389671326,准确率0.8405639097744361\n",
            "轮次7,损失0.5085390394744153,        时间590.7571382522583,准确率0.841044776119403\n",
            "轮次7,损失0.5066406188941858,        时间595.0401146411896,准确率0.8415481481481482\n",
            "轮次7,损失0.5046238854965789,        时间599.179886341095,准确率0.8422132352941176\n",
            "轮次7,损失0.5025578265463236,        时间603.7685782909393,准确率0.8428102189781022\n",
            "轮次7,损失0.5006797694424311,        时间607.5106363296509,准确率0.8433768115942029\n",
            "轮次7,损失0.49897562756419017,        时间611.2610659599304,准确率0.8438273381294964\n",
            "轮次7,损失0.49746531638654656,        时间615.8230831623077,准确率0.8443\n",
            "轮次8,损失0.4956663680863862,        时间619.8921411037445,准确率0.844822695035461\n",
            "轮次8,损失0.4933362202615119,        时间624.1733798980713,准确率0.8455774647887324\n",
            "轮次8,损失0.49099587078536916,        时间628.9311735630035,准确率0.8463146853146853\n",
            "轮次8,损失0.4887606080642824,        时间633.0340447425842,准确率0.8469861111111111\n",
            "轮次8,损失0.48665118412193964,        时间637.0087797641754,准确率0.8476206896551725\n",
            "轮次8,损失0.48487131503099046,        时间641.9014704227448,准确率0.8481917808219178\n",
            "轮次8,损失0.48269043301477027,        时间645.6290571689606,准确率0.8488843537414966\n",
            "轮次8,损失0.4806661705384823,        时间649.9406197071075,准确率0.849527027027027\n",
            "轮次8,损失0.47895455738595993,        时间654.3737077713013,准确率0.8500402684563758\n",
            "轮次8,损失0.4770921335347589,        时间658.1227021217346,准确率0.8506133333333333\n",
            "轮次8,损失0.47534925974888975,        时间662.127682685852,准确率0.8511192052980132\n",
            "轮次8,损失0.4737595312999141,        时间667.4449803829193,准确率0.8515263157894737\n",
            "轮次8,损失0.4724070207879724,        时间671.5915122032166,准确率0.8519542483660131\n",
            "轮次8,损失0.47064068550263466,        时间675.2939019203186,准确率0.8525\n",
            "轮次8,损失0.46926106345282603,        时间679.8016309738159,准确率0.8528774193548387\n",
            "轮次8,损失0.46746690478859854,        时间683.7428026199341,准确率0.8534038461538461\n",
            "轮次8,损失0.4658630281419555,        时间688.020429611206,准确率0.853859872611465\n",
            "轮次8,损失0.4644259788630711,        时间692.7215099334717,准确率0.8542721518987342\n",
            "轮次8,损失0.4627910327998609,        时间696.7672882080078,准确率0.8547232704402515\n",
            "轮次8,损失0.4616051075192853,        时间701.2335028648376,准确率0.855025\n",
            "轮次9,损失0.4601698347049386,        时间705.8020415306091,准确率0.8555093167701864\n",
            "轮次9,损失0.4581291015950791,        时间710.3258683681488,准确率0.8561481481481481\n",
            "轮次9,损失0.4563542131550777,        时间715.4706337451935,准确率0.8566625766871165\n",
            "轮次9,损失0.454495537053397,        时间719.9218039512634,准确率0.8572317073170732\n",
            "轮次9,损失0.45261613616081364,        时间723.8905262947083,准确率0.8577878787878788\n",
            "轮次9,损失0.4509180500097521,        时间729.2424809932709,准确率0.8583132530120482\n",
            "轮次9,损失0.4493704312559075,        时间733.8255143165588,准确率0.8587305389221557\n",
            "轮次9,损失0.44780669730596995,        时间739.0755758285522,准确率0.8591607142857143\n",
            "轮次9,损失0.44651931357351127,        时间743.4229459762573,准确率0.8595443786982249\n",
            "轮次9,损失0.4449047443870012,        时间747.3792641162872,准确率0.8600058823529412\n",
            "轮次9,损失0.4432538791301617,        时间752.0829126834869,准确率0.8605087719298246\n",
            "轮次9,损失0.4420339471371924,        时间756.6578741073608,准确率0.8608895348837209\n",
            "轮次9,损失0.44054899046902285,        时间761.2580742835999,准确率0.8613526011560694\n",
            "轮次9,损失0.4391552082978836,        时间766.2214698791504,准确率0.8617528735632184\n",
            "轮次9,损失0.4377849550459662,        时间770.901624917984,准确率0.8621714285714286\n",
            "轮次9,损失0.43662024872947724,        时间776.0794231891632,准确率0.8625284090909091\n",
            "轮次9,损失0.43530098909341164,        时间780.4936964511871,准确率0.8629209039548023\n",
            "轮次9,损失0.43393087570822675,        时间784.9102420806885,准确率0.863314606741573\n",
            "轮次9,损失0.4327103473048565,        时间789.7681062221527,准确率0.8636759776536312\n",
            "轮次9,损失0.431286952676835,        时间794.2475669384003,准确率0.8641\n",
            "轮次10,损失0.4302147009694361,        时间798.66304063797,准确率0.8643812154696132\n",
            "轮次10,损失0.4284542322224684,        时间803.5501537322998,准确率0.8649285714285714\n",
            "轮次10,损失0.42684400583231946,        时间807.5440247058868,准确率0.8654207650273225\n",
            "轮次10,损失0.4252905148982461,        时间812.1007566452026,准确率0.8658913043478261\n",
            "轮次10,损失0.4239980757301938,        时间816.3289391994476,准确率0.866281081081081\n",
            "轮次10,损失0.4227259825911116,        时间820.7696673870087,准确率0.8666827956989247\n",
            "轮次10,损失0.42140720072414617,        时间825.9518761634827,准确率0.867096256684492\n",
            "轮次10,损失0.42021005927647764,        时间830.623161315918,准确率0.8674042553191489\n",
            "轮次10,损失0.41897161382924464,        时间835.9328231811523,准确率0.8677354497354497\n",
            "轮次10,损失0.4176445045469381,        时间840.7817993164062,准确率0.8681736842105263\n",
            "轮次10,损失0.41635841717636557,        时间844.4126358032227,准确率0.8685549738219895\n",
            "轮次10,损失0.41497614263313326,        时间848.5870988368988,准确率0.868953125\n",
            "轮次10,损失0.4139383652694784,        时间854.0147366523743,准确率0.8692227979274612\n",
            "轮次10,损失0.4126391653991481,        时间858.163227558136,准确率0.8696185567010309\n",
            "轮次10,损失0.41148927427101784,        时间862.7531025409698,准确率0.869948717948718\n",
            "轮次10,损失0.4105358898054322,        时间866.813149690628,准确率0.8702244897959184\n",
            "轮次10,损失0.4095066899908711,        时间870.9789497852325,准确率0.870507614213198\n",
            "轮次10,损失0.4083808872350928,        时间875.8344924449921,准确率0.8708535353535354\n",
            "轮次10,损失0.40730222408629835,        时间880.2564089298248,准确率0.8711658291457286\n",
            "轮次10,损失0.4062260528530337,        时间885.2020397186279,准确率0.87146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 练习\n",
        "class lstm(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    #定义lstm层\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "    #定义线性层处理lstm层返回的数据 hidden_size,18\n",
        "    self.liner = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self,input,hidden,c):\n",
        "    input = input.unsqueeze(1)\n",
        "    rr,(hn,cn) = self.lstm(input,(hidden,c))\n",
        "    #取最后一个时间步的输出,然后经过线性层输出到softmax\n",
        "    return self.softmax(self.liner(rr[-1])),hn,cn\n",
        "\n",
        "  def inithidden(self):\n",
        "    hidden  = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "    c = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "    return hidden,c"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1pfYaGHW0jin"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 测试结果\n",
        "# 1 实例化rnn对象\n",
        "mylstm = lstm(57, 128, 18)\n",
        "print('lstm--->', mylstm)\n",
        "\n",
        "# 2 准备数据\n",
        "input = torch.randn(6, 57)\n",
        "print(input.shape)\n",
        "h,c = mylstm.inithidden()\n",
        "\n",
        "# 3 给模型1次性的送数据\n",
        "# [seqlen, 57], [1, 1, 128]) -> [1,18], [1,1,128]\n",
        "output, h,c = mylstm(input, h,c)\n",
        "print('一次性的送数据：output->', output.shape, output)\n",
        "print('hidden->', h.shape)\n",
        "print('outpur->', output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "hyIJXDLf4tEO",
        "outputId": "5b38efca-41b4-4f27-fa1d-aa8439871b35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm---> lstm(\n",
            "  (lstm): LSTM(57, 128)\n",
            "  (liner): Linear(in_features=128, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax(dim=-1)\n",
            ")\n",
            "torch.Size([6, 57])\n",
            "一次性的送数据：output-> torch.Size([1, 18]) tensor([[-2.8638, -2.9164, -2.9041, -2.8995, -2.8628, -2.8157, -2.9376, -2.7969,\n",
            "         -2.8231, -2.8488, -3.0521, -3.0163, -2.7905, -2.8855, -3.0211, -2.7957,\n",
            "         -2.9637, -2.8866]], grad_fn=<LogSoftmaxBackward0>)\n",
            "hidden-> torch.Size([1, 1, 128])\n",
            "outpur-> torch.Size([1, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GRU训练\n",
        "lr = 1e-3\n",
        "epochs = 10\n",
        "path = \"/content/drive/MyDrive/NLP/data/name_classfication.txt\"\n",
        "x,y = read_data(path)\n",
        "def train_gru(x,y):\n",
        "  # 检查是否有可用的CUDA设备\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  #实例化dataloader\n",
        "  namedataloader = get_traindata()\n",
        "  input_size = all_letters\n",
        "  hidden_size = 200\n",
        "  output_size = categorynum\n",
        "  #实例化模型\n",
        "  my_gru = myGRU(input_size=n_letters,\n",
        "                 hidden_size=hidden_size,\n",
        "                 output_size=categorynum).to(device) # 将模型移动到GPU\n",
        "\n",
        "  loss_fn = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(my_gru.parameters(), lr=lr)\n",
        "\n",
        "  starttime = time.time()\n",
        "  total_iter_num = 0 #已经训练的样本数\n",
        "  total_loss = 0  #已经训练的损失和\n",
        "  total_loss_list = [] #每批样本求一次平均损失\n",
        "  total_acc_num = 0 #训练样本准确总数\n",
        "  total_acc_list = [] #平均准确率列表\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for i,(x,y) in enumerate(namedataloader):\n",
        "      x,y = x.to(device), y.to(device) # 将数据移动到GPU\n",
        "      hidden = my_gru.inithidden().to(device) # 将隐藏层初始化数据移动到GPU\n",
        "      output,hidden = my_gru(x[0],hidden)\n",
        "      loss = loss_fn(output,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #计算损失\n",
        "      total_iter_num = total_iter_num + 1\n",
        "      total_loss = total_loss + loss.item()\n",
        "      #计算准确率\n",
        "      i_predit_tag = (1 if torch.argmax(output).item() == y.item() else 0)\n",
        "      total_acc_num = total_acc_num + i_predit_tag\n",
        "      #每100次训练计算一次平均损失\n",
        "      if (total_iter_num % 100 == 0):\n",
        "        tmploss = total_loss / total_iter_num\n",
        "        total_loss_list.append(tmploss)\n",
        "\n",
        "        tmpacc = total_acc_num / total_iter_num\n",
        "        total_acc_list.append(tmpacc)\n",
        "      #每1000次训练打印日志\n",
        "      if (total_iter_num % 1000 == 0):\n",
        "        total_time = time.time() - starttime\n",
        "        print(f'轮次{epoch+1},损失{tmploss},\\\n",
        "        时间{time.time()-starttime},准确率{tmpacc}')\n",
        "  #计算总时间\n",
        "  total_time = int(time.time() - starttime)\n",
        "  #保存训练好的模型\n",
        "  torch.save(my_gru.state_dict(), '/content/drive/MyDrive/NLP/model/my_GRU_model.bin')\n",
        "  return total_gloss_list, total_gtime, total_gacc_list\n",
        "\n",
        "total_gloss_list, total_gtime, total_gacc_list = train_gru(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR3RB6YfyzPw",
        "outputId": "db79e13e-95a8-442a-cc6b-705f73fc4f4a",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 57]) torch.Size([1])\n",
            "轮次1,损失1.6322850541314111,        时间5.990103006362915,准确率0.527\n",
            "轮次1,损失1.4738219224444764,        时间12.214769840240479,准确率0.5675\n",
            "轮次1,损失1.3465313925225346,        时间16.78200387954712,准确率0.6013333333333334\n",
            "轮次1,损失1.2789282852087782,        时间22.182300567626953,准确率0.62175\n",
            "轮次1,损失1.229536491682788,        时间27.89604353904724,准确率0.6376\n",
            "轮次1,损失1.1953144368798287,        时间32.67821025848389,准确率0.6491666666666667\n",
            "轮次1,损失1.1590513167119634,        时间38.45380902290344,准确率0.6574285714285715\n",
            "轮次1,损失1.1273756939817803,        时间44.22819495201111,准确率0.666125\n",
            "轮次1,损失1.0941237649483284,        时间52.00665473937988,准确率0.675\n",
            "轮次1,损失1.073689895499401,        时间56.61921429634094,准确率0.6801\n",
            "轮次1,损失1.0525225554892876,        时间62.14335560798645,准确率0.6884545454545454\n",
            "轮次1,损失1.032260973764196,        时间67.43401956558228,准确率0.69275\n",
            "轮次1,损失1.0142710666316588,        时间77.0105414390564,准确率0.6974615384615385\n",
            "轮次1,损失0.9942728070722333,        时间82.64383745193481,准确率0.7020714285714286\n",
            "轮次1,损失0.9745691978433338,        时间88.56484580039978,准确率0.7082\n",
            "轮次1,损失0.961385305027829,        时间93.24656629562378,准确率0.712375\n",
            "轮次1,损失0.9468348082602819,        时间101.25079846382141,准确率0.7165882352941176\n",
            "轮次1,损失0.9351040849568802,        时间107.40199160575867,准确率0.7197222222222223\n",
            "轮次1,损失0.924536769229726,        时间114.31835174560547,准确率0.7225263157894737\n",
            "轮次1,损失0.9142118610557239,        时间119.9689519405365,准确率0.7252\n",
            "轮次2,损失0.9019340862270834,        时间125.87492418289185,准确率0.728047619047619\n",
            "轮次2,损失0.8896987239175259,        时间130.72735691070557,准确率0.7310909090909091\n",
            "轮次2,损失0.8789509003983944,        时间136.0456030368805,准确率0.7339565217391304\n",
            "轮次2,损失0.8633856819048775,        时间141.19930291175842,准确率0.7383333333333333\n",
            "轮次2,损失0.8533350432109656,        时间145.79866933822632,准确率0.74128\n",
            "轮次2,损失0.8427876981445942,        时间151.2269937992096,准确率0.7447307692307692\n",
            "轮次2,损失0.8357457845204928,        时间156.28760981559753,准确率0.7462592592592593\n",
            "轮次2,损失0.8282251919076302,        时间163.61172366142273,准确率0.7486785714285714\n",
            "轮次2,损失0.821046407219074,        时间168.91816473007202,准确率0.7503793103448276\n",
            "轮次2,损失0.8131861183030923,        时间174.98927354812622,准确率0.7526666666666667\n",
            "轮次2,损失0.8035887859093822,        时间180.83808302879333,准确率0.7554516129032258\n",
            "轮次2,损失0.7977430972083266,        时间186.2866930961609,准确率0.7569375\n",
            "轮次2,损失0.789793059861829,        时间197.7165608406067,准确率0.7591212121212121\n",
            "轮次2,损失0.7827498941184788,        时间203.5844542980194,准确率0.7612941176470588\n",
            "轮次2,损失0.7761509107271595,        时间210.08795046806335,准确率0.7631428571428571\n",
            "轮次2,损失0.770994722559679,        时间218.0198962688446,准确率0.7648888888888888\n",
            "轮次2,损失0.765947429178731,        时间223.15495491027832,准确率0.7659459459459459\n",
            "轮次2,损失0.7588708082692898,        时间229.04142832756042,准确率0.7676315789473684\n",
            "轮次2,损失0.7538505692847534,        时间234.15875816345215,准确率0.7691282051282051\n",
            "轮次2,损失0.7482115796566008,        时间239.6159873008728,准确率0.771\n",
            "轮次3,损失0.7427566607491062,        时间244.7142243385315,准确率0.7725853658536586\n",
            "轮次3,损失0.735198488404552,        时间251.70429229736328,准确率0.7747142857142857\n",
            "轮次3,损失0.7277806269496014,        时间256.4191827774048,准确率0.7766976744186046\n",
            "轮次3,损失0.7232958453664258,        时间263.01831912994385,准确率0.7779318181818182\n",
            "轮次3,损失0.7175318799487973,        时间268.83615732192993,准确率0.7793777777777777\n",
            "轮次3,损失0.7125763930481069,        时间274.7207908630371,准确率0.7808478260869566\n",
            "轮次3,损失0.7074940984639141,        时间280.6985056400299,准确率0.7821063829787234\n",
            "轮次3,损失0.702311374505344,        时间285.0759403705597,准确率0.7837708333333333\n",
            "轮次3,损失0.697534119581694,        时间291.0991017818451,准确率0.785\n",
            "轮次3,损失0.6928198703778958,        时间297.1192617416382,准确率0.78638\n",
            "轮次3,损失0.6889988278696221,        时间302.84021377563477,准确率0.7875294117647059\n",
            "轮次3,损失0.6842967633871416,        时间307.56949257850647,准确率0.789\n",
            "轮次3,损失0.6805411971893389,        时间314.1410536766052,准确率0.7900566037735849\n",
            "轮次3,损失0.6760149287651323,        时间319.88832902908325,准确率0.7911851851851852\n",
            "轮次3,损失0.6720145349361442,        时间325.99862360954285,准确率0.7921636363636364\n",
            "轮次3,损失0.6679204071153365,        时间330.4839994907379,准确率0.7933571428571429\n",
            "轮次3,损失0.6642984650450994,        时间335.9632215499878,准确率0.794578947368421\n",
            "轮次3,损失0.6604069782259503,        时间342.129909992218,准确率0.7956551724137931\n",
            "轮次3,损失0.6573605527166781,        时间346.810275554657,准确率0.796593220338983\n",
            "轮次3,损失0.6546571158975504,        时间353.3418848514557,准确率0.79725\n",
            "轮次4,损失0.6493222318463031,        时间359.23352336883545,准确率0.7987213114754098\n",
            "轮次4,损失0.6446182442249626,        时间366.3082754611969,准确率0.8001451612903225\n",
            "轮次4,损失0.6409006416121092,        时间371.0122125148773,准确率0.8012698412698412\n",
            "轮次4,损失0.636748251327974,        时间376.08281922340393,准确率0.802578125\n",
            "轮次4,损失0.6329928564350071,        时间381.72600293159485,准确率0.8036461538461539\n",
            "轮次4,损失0.6290861343102411,        时间387.0897252559662,准确率0.8047121212121212\n",
            "轮次4,损失0.6258807277400561,        时间392.6551926136017,准确率0.8054925373134328\n",
            "轮次4,损失0.6223017619564899,        时间398.3589849472046,准确率0.8063235294117647\n",
            "轮次4,损失0.6189985335098289,        时间403.627206325531,准确率0.8071594202898551\n",
            "轮次4,损失0.6155026418914905,        时间407.70977115631104,准确率0.8081571428571429\n",
            "轮次4,损失0.611709336992007,        时间413.9858753681183,准确率0.8091971830985916\n",
            "轮次4,损失0.6082150894376676,        时间419.47205233573914,准确率0.8102361111111112\n",
            "轮次4,损失0.6055255299161579,        时间424.74354672431946,准确率0.8111506849315069\n",
            "轮次4,损失0.6030197335205509,        时间429.7771530151367,准确率0.8117702702702703\n",
            "轮次4,损失0.6000899312953902,        时间434.9268956184387,准确率0.8126\n",
            "轮次4,损失0.5976159846224858,        时间440.9863405227661,准确率0.8132236842105263\n",
            "轮次4,损失0.5952137347445942,        时间446.3717141151428,准确率0.8138831168831169\n",
            "轮次4,损失0.5922653902393291,        时间452.03028440475464,准确率0.8147435897435897\n",
            "轮次4,损失0.5898850730986626,        时间457.34514474868774,准确率0.8155443037974683\n",
            "轮次4,损失0.5875369130328368,        时间463.13365840911865,准确率0.8160875\n",
            "轮次5,损失0.5843311265195089,        时间468.1084566116333,准确率0.8171234567901234\n",
            "轮次5,损失0.5803003724292212,        时间473.81308674812317,准确率0.8184146341463414\n",
            "轮次5,损失0.5764862914828629,        时间478.37351512908936,准确率0.8194578313253013\n",
            "轮次5,损失0.5732806557712057,        时间483.2271354198456,准确率0.8203809523809524\n",
            "轮次5,损失0.5706529888876497,        时间489.37210273742676,准确率0.8211294117647059\n",
            "轮次5,损失0.5677176595449631,        时间494.4238703250885,准确率0.8219767441860465\n",
            "轮次5,损失0.564606796161178,        时间500.1636245250702,准确率0.8229080459770115\n",
            "轮次5,损失0.5617060618092501,        时间505.1159920692444,准确率0.8238068181818182\n",
            "轮次5,损失0.5590963699021196,        时间510.4769666194916,准确率0.8245955056179776\n",
            "轮次5,损失0.5565080096617606,        时间515.1776511669159,准确率0.8252666666666667\n",
            "轮次5,损失0.5540140549717216,        时间520.433789730072,准确率0.8259010989010989\n",
            "轮次5,损失0.5512211738707365,        时间526.2621576786041,准确率0.8267934782608696\n",
            "轮次5,损失0.5487575147333007,        时间531.5673637390137,准确率0.8273870967741935\n",
            "轮次5,损失0.5461433450118653,        时间537.2038826942444,准确率0.828031914893617\n",
            "轮次5,损失0.5437380675615893,        时间541.7211103439331,准确率0.8287368421052631\n",
            "轮次5,损失0.5417627470138313,        时间547.4561159610748,准确率0.8293229166666667\n",
            "轮次5,损失0.5402362364566027,        时间552.9825036525726,准确率0.8297938144329897\n",
            "轮次5,损失0.5382571467654761,        时间558.9261410236359,准确率0.8303775510204081\n",
            "轮次5,损失0.5361333935567637,        时间563.6810326576233,准确率0.831040404040404\n",
            "轮次5,损失0.5339431083905244,        时间569.2720355987549,准确率0.83163\n",
            "轮次6,损失0.5318769557279468,        时间575.5923039913177,准确率0.8322673267326732\n",
            "轮次6,损失0.5290349296784262,        时间580.3178925514221,准确率0.8331176470588235\n",
            "轮次6,损失0.5262869059569116,        时间585.4745681285858,准确率0.8340485436893204\n",
            "轮次6,损失0.5232646226247009,        时间590.0660092830658,准确率0.8350096153846154\n",
            "轮次6,损失0.5204543895631262,        时间595.7159399986267,准确率0.8358666666666666\n",
            "轮次6,损失0.5178151263387548,        时间601.1883523464203,准确率0.836688679245283\n",
            "轮次6,损失0.5155705777919359,        时间606.3792064189911,准确率0.8372803738317757\n",
            "轮次6,损失0.5134350719474498,        时间612.4796779155731,准确率0.8379444444444445\n",
            "轮次6,损失0.5110239858541853,        时间616.7873928546906,准确率0.8386788990825688\n",
            "轮次6,损失0.508698312675436,        时间622.5040850639343,准确率0.8393636363636363\n",
            "轮次6,损失0.5067275004591576,        时间627.5559592247009,准确率0.839990990990991\n",
            "轮次6,损失0.5048278229549561,        时间632.9001660346985,准确率0.8405357142857143\n",
            "轮次6,损失0.5026812662258083,        时间637.6552288532257,准确率0.8411858407079646\n",
            "轮次6,损失0.5010496461137752,        时间642.618506193161,准确率0.8416228070175439\n",
            "轮次6,损失0.499116684458536,        时间648.1362009048462,准确率0.8421478260869565\n",
            "轮次6,损失0.4975994788516684,        时间652.7686495780945,准确率0.8425775862068966\n",
            "轮次6,损失0.49590116177657,        时间658.6262753009796,准确率0.8430427350427351\n",
            "轮次6,损失0.4948240653705876,        时间663.7360355854034,准确率0.843406779661017\n",
            "轮次6,损失0.49326051122332265,        时间669.0058386325836,准确率0.8438235294117648\n",
            "轮次6,损失0.49135454325776334,        时间674.0734293460846,准确率0.8443916666666667\n",
            "轮次7,损失0.4895626849137627,        时间679.0173399448395,准确率0.8449504132231405\n",
            "轮次7,损失0.4871515269403781,        时间684.5092897415161,准确率0.8457131147540984\n",
            "轮次7,损失0.4849240847218852,        时间688.7948138713837,准确率0.8462926829268292\n",
            "轮次7,损失0.48267515621537654,        时间694.7144331932068,准确率0.8470241935483871\n",
            "轮次7,损失0.48040135805396206,        时间699.5954151153564,准确率0.847736\n",
            "轮次7,损失0.4787177449375642,        时间704.2313168048859,准确率0.8482698412698413\n",
            "轮次7,损失0.4767755455593174,        时间709.2947516441345,准确率0.8487952755905512\n",
            "轮次7,损失0.47455159613710896,        时间714.0352835655212,准确率0.849484375\n",
            "轮次7,损失0.4727551605948421,        时间719.2039740085602,准确率0.850031007751938\n",
            "轮次7,损失0.4709526658846565,        时间723.8095605373383,准确率0.8506\n",
            "轮次7,损失0.4692408433845065,        时间728.1562383174896,准确率0.8510687022900764\n",
            "轮次7,损失0.4673922905707765,        时间733.2134394645691,准确率0.8516742424242424\n",
            "轮次7,损失0.46569847631407346,        时间738.0214741230011,准确率0.852203007518797\n",
            "轮次7,损失0.46419754398604646,        时间743.069171667099,准确率0.8526268656716418\n",
            "轮次7,损失0.4626698487213803,        时间748.8828356266022,准确率0.8531185185185185\n",
            "轮次7,损失0.4610218612246428,        时间753.7437047958374,准确率0.8535735294117647\n",
            "轮次7,损失0.4593552028003674,        时间758.3972864151001,准确率0.854087591240876\n",
            "轮次7,损失0.4575556440318387,        时间762.9999306201935,准确率0.8546884057971015\n",
            "轮次7,损失0.4567259938436854,        时间768.5967676639557,准确率0.8549568345323741\n",
            "轮次7,损失0.4554216463789859,        时间773.3776748180389,准确率0.8553642857142857\n",
            "轮次8,损失0.4539139376790553,        时间778.595424413681,准确率0.8558368794326241\n",
            "轮次8,损失0.4519958306846661,        时间783.5504956245422,准确率0.8564154929577464\n",
            "轮次8,损失0.45023221881388975,        时间788.6927070617676,准确率0.8569300699300699\n",
            "轮次8,损失0.4483181149488063,        时间794.2551436424255,准确率0.8574791666666667\n",
            "轮次8,损失0.44672237382405805,        时间799.3711638450623,准确率0.8579724137931034\n",
            "轮次8,损失0.4450142197800068,        时间804.7791998386383,准确率0.8584794520547945\n",
            "轮次8,损失0.4435298463401095,        时间809.3792796134949,准确率0.8589523809523809\n",
            "轮次8,损失0.441790211853214,        时间813.5626904964447,准确率0.8595067567567568\n",
            "轮次8,损失0.44009608156916463,        时间819.0384430885315,准确率0.8600335570469798\n",
            "轮次8,损失0.4385582831195414,        时间823.5549740791321,准确率0.8605466666666667\n",
            "轮次8,损失0.4370723190986883,        时间828.5694913864136,准确率0.8609867549668874\n",
            "轮次8,损失0.43578622187039584,        时间833.1416654586792,准确率0.8613947368421052\n",
            "轮次8,损失0.4346282644745,        时间837.7796008586884,准确率0.8617581699346405\n",
            "轮次8,损失0.4334522098376182,        时间842.6556901931763,准确率0.8621103896103897\n",
            "轮次8,损失0.43236957935636955,        时间847.3103084564209,准确率0.8624451612903226\n",
            "轮次8,损失0.4308181554547479,        时间853.4837145805359,准确率0.862948717948718\n",
            "轮次8,损失0.4296294002160368,        时间858.7645065784454,准确率0.8632547770700637\n",
            "轮次8,损失0.42831589956886024,        时间863.7992970943451,准确率0.8636329113924051\n",
            "轮次8,损失0.42706020629074365,        时间869.2830271720886,准确率0.8640251572327045\n",
            "轮次8,损失0.42585646465031934,        时间873.5086426734924,准确率0.86438125\n",
            "轮次9,损失0.42472793423631794,        时间878.6682903766632,准确率0.8646956521739131\n",
            "轮次9,损失0.4230959931836227,        时间882.8065803050995,准确率0.8652098765432099\n",
            "轮次9,损失0.4215967678097507,        时间887.5912322998047,准确率0.8657055214723927\n",
            "轮次9,损失0.4199230607403007,        时间893.2990629673004,准确率0.8662317073170732\n",
            "轮次9,损失0.4184146476745345,        时间898.344432592392,准确率0.8667090909090909\n",
            "轮次9,损失0.41684571909132057,        时间903.8160898685455,准确率0.8672048192771085\n",
            "轮次9,损失0.4156077599914293,        时间908.5449438095093,准确率0.867568862275449\n",
            "轮次9,损失0.4143842051085192,        时间913.1482224464417,准确率0.8679285714285714\n",
            "轮次9,损失0.413161742540723,        时间917.9237389564514,准确率0.8682899408284024\n",
            "轮次9,损失0.4118721821377083,        时间922.4304084777832,准确率0.8687058823529412\n",
            "轮次9,损失0.41078654170829565,        时间928.0556871891022,准确率0.8690175438596491\n",
            "轮次9,损失0.40965568915515027,        时间932.9777736663818,准确率0.8693546511627906\n",
            "轮次9,损失0.4085168582222095,        时间939.6100378036499,准确率0.8696589595375722\n",
            "轮次9,损失0.4074899824064297,        时间944.4425427913666,准确率0.8699655172413793\n",
            "轮次9,损失0.4065920345086339,        时间948.981461763382,准确率0.8702342857142857\n",
            "轮次9,损失0.40523951128826297,        时间954.1374921798706,准确率0.8706761363636364\n",
            "轮次9,损失0.40404118103845815,        时间958.2582519054413,准确率0.8710564971751412\n",
            "轮次9,损失0.40290370072550247,        时间963.4601373672485,准确率0.8714044943820225\n",
            "轮次9,损失0.4019064974199918,        时间968.5013997554779,准确率0.8717262569832402\n",
            "轮次9,损失0.40104273654597533,        时间972.8447442054749,准确率0.8719333333333333\n",
            "轮次10,损失0.4001973766789614,        时间977.9904804229736,准确率0.8721933701657458\n",
            "轮次10,损失0.3987469646406354,        时间982.4835870265961,准确率0.8726593406593407\n",
            "轮次10,损失0.39735430748494494,        时间987.3831768035889,准确率0.8730874316939891\n",
            "轮次10,损失0.3960455933181392,        时间992.7939574718475,准确率0.8735108695652174\n",
            "轮次10,损失0.3947202911550342,        时间997.3199248313904,准确率0.873945945945946\n",
            "轮次10,损失0.39350805129254246,        时间1002.4963042736053,准确率0.8743118279569893\n",
            "轮次10,损失0.39233005063589604,        时间1007.5812079906464,准确率0.8746951871657754\n",
            "轮次10,损失0.39127771482969664,        时间1013.4441430568695,准确率0.8750531914893617\n",
            "轮次10,损失0.39023176312033503,        时间1017.9848065376282,准确率0.8753439153439153\n",
            "轮次10,损失0.3892390528946825,        时间1022.3936257362366,准确率0.8756315789473684\n",
            "轮次10,损失0.3883957687233082,        时间1027.4886586666107,准确率0.8759319371727748\n",
            "轮次10,损失0.38724302289161094,        时间1031.737543106079,准确率0.8762760416666666\n",
            "轮次10,损失0.386352821725881,        时间1037.1113111972809,准确率0.8765647668393782\n",
            "轮次10,损失0.38531328442584534,        时间1041.5844004154205,准确率0.8768814432989691\n",
            "轮次10,损失0.384338357384457,        时间1046.013027191162,准确率0.8771538461538462\n",
            "轮次10,损失0.3833942896533547,        时间1051.1093554496765,准确率0.8774234693877551\n",
            "轮次10,损失0.38235105708060235,        时间1055.55926156044,准确率0.877751269035533\n",
            "轮次10,损失0.3814061340968841,        时间1059.8476507663727,准确率0.8780252525252525\n",
            "轮次10,损失0.38043240950328383,        时间1065.0889267921448,准确率0.8783668341708543\n",
            "轮次10,损失0.37961217976148376,        时间1069.229679107666,准确率0.878585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 绘制对比图\n",
        "# 绘制损失对比曲线\n",
        "# 创建画布0\n",
        "plt.figure(0)\n",
        "# # 绘制损失对比曲线\n",
        "plt.plot(total_loss_list, label=\"RNN\")\n",
        "plt.plot(total_lloss_list, color=\"red\", label=\"LSTM\")\n",
        "plt.plot(total_gloss_list, color=\"orange\", label=\"GRU\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig('RNN_LSTM_GRU_loss2.png')\n",
        "plt.show()\n",
        "\n",
        "# 绘制柱状图\n",
        "# 创建画布1\n",
        "plt.figure(1)\n",
        "x_data = [\"RNN\", \"LSTM\", \"GRU\"]\n",
        "y_data = [total_time, total_ltime, total_gtime]\n",
        "# 绘制训练耗时对比柱状图\n",
        "plt.bar(range(len(x_data)), y_data, tick_label=x_data)\n",
        "plt.savefig('RNN_LSTM_GRU_period2.png')\n",
        "plt.show()\n",
        "\n",
        "# 绘制准确率对比曲线\n",
        "plt.figure(2)\n",
        "plt.plot(total_acc_list, label=\"RNN\")\n",
        "plt.plot(total_lacc_list, color=\"red\", label=\"LSTM\")\n",
        "plt.plot(total_gacc_list, color=\"orange\", label=\"GRU\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig('RNN_LSTM_GRU_acc2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gStAb1Mr-AKJ",
        "outputId": "e66ce2da-08de-4583-c9d1-68cd327ca539",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fd239ee90>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fde2ab790>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fd157c650>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3fd1656e50>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fd0b3dbd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fd0b3c150>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c3fd063a090>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3fd16a2290>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 预测结果\n",
        "# 将人名转化为onehot张量\n",
        "# eg 'bai' --> [3,57]\n",
        "def NameToTensor(x):\n",
        "  tensor_x = torch.zeros(len(x),n_letters)\n",
        "  for i,letter in enumerate(x):\n",
        "    tensor_x[i][all_letters.find(letter)] = 1\n",
        "  return tensor_x"
      ],
      "metadata": {
        "id": "Gf2ui48v8vkf",
        "cellView": "form"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RRN预测\n",
        "def predict_rnn(x):\n",
        "  # n_letters = n_letters # Removed to use global n_letters\n",
        "  # n_hidden = 200 # Removed to use global n_hidden\n",
        "  # n_countries = categorynum # Removed to use global n_countries\n",
        "\n",
        "  x_tensor = NameToTensor(x)\n",
        "\n",
        "  my_rnn = myRNN(input_size=n_letters, hidden_size=200, output_size=categorynum)\n",
        "  my_rnn.load_state_dict(torch.load('my_rnn_model.bin'))\n",
        "  my_rnn.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output,hidden = my_rnn(x_tensor,my_rnn.inithidden())\n",
        "    # Get the index of the highest probability\n",
        "    topi = torch.argmax(output, dim=1)\n",
        "    country_idx = topi[0].item()\n",
        "    country = categorys[country_idx]\n",
        "    print(\"rnn-->\",x)\n",
        "    print(f\"Predicted category: {country}\")"
      ],
      "metadata": {
        "id": "VwG7DUSmSUxU",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LSTM预测\n",
        "def predict_lstm(x):\n",
        "  # n_letters = n_letters # Removed to use global n_letters\n",
        "  # n_hidden = 200 # Removed to use global n_hidden\n",
        "  # n_countries = categorynum # Removed to use global n_countries\n",
        "\n",
        "  x_tensor = NameToTensor(x)\n",
        "\n",
        "  my_lstm = myLSTM(input_size=n_letters, hidden_size=200, output_size=categorynum)\n",
        "  my_lstm.load_state_dict(torch.load('my_lstm_model.bin'))\n",
        "  my_lstm.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    hidden,c = my_lstm.inithidden()\n",
        "    output,hidden,c = my_lstm(x_tensor,hidden,c)\n",
        "    # Get the index of the highest probability\n",
        "    topi = torch.argmax(output, dim=1)\n",
        "    country_idx = topi[0].item()\n",
        "    country = categorys[country_idx]\n",
        "    print(\"lstm-->\",x) # Changed from rnn--> to lstm--> for clarity\n",
        "    print(f\"Predicted category: {country}\")"
      ],
      "metadata": {
        "id": "kOen9cAE2GK_",
        "cellView": "form"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GRU预测\n",
        "def predict_gru(x):\n",
        "  # n_letters = n_letters # Removed to use global n_letters\n",
        "  # n_hidden = 200 # Removed to use global n_hidden\n",
        "  # n_countries = categorynum # Removed to use global n_countries\n",
        "\n",
        "  x_tensor = NameToTensor(x)\n",
        "\n",
        "  my_gru = myGRU(input_size=n_letters, hidden_size=200, output_size=categorynum)\n",
        "  my_gru.load_state_dict(torch.load('my_GRU_model.bin'))\n",
        "  my_gru.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output,hidden = my_gru(x_tensor,my_gru.inithidden())\n",
        "    # Get the index of the highest probability\n",
        "    topi = torch.argmax(output, dim=1)\n",
        "    country_idx = topi[0].item()\n",
        "    country = categorys[country_idx]\n",
        "    print(\"gru-->\",x) # Changed from rnn--> to gru--> for clarity\n",
        "    print(f\"Predicted category: {country}\")"
      ],
      "metadata": {
        "id": "emIWzlOr2J0p",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 预测调用\n",
        "def dm_test_predic_rnn_lstm_gru():\n",
        "        # 把三个函数的入口地址 组成列表，统一输入数据进行测试\n",
        "    for func in [predict_rnn, predict_lstm, predict_gru]:\n",
        "        func('Teng')"
      ],
      "metadata": {
        "id": "E5wdQll-2LOl",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm_test_predic_rnn_lstm_gru()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "AhAIqy_13NMj",
        "outputId": "2af68f36-e571-4f93-de73-0393ade9e84c",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'my_rnn_model.bin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-910874450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdm_test_predic_rnn_lstm_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-19-4018238123.py\u001b[0m in \u001b[0;36mdm_test_predic_rnn_lstm_gru\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# 把三个函数的入口地址 组成列表，统一输入数据进行测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_gru\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Teng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-15-607070612.py\u001b[0m in \u001b[0;36mpredict_rnn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmy_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorynum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmy_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_rnn_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mmy_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_rnn_model.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f584926",
        "outputId": "85c17694-575f-4bfa-856e-e5b93f3d7fe2"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_count = torch.cuda.device_count()\n",
        "    print(f\"Number of CUDA devices: {device_count}\")\n",
        "    for i in range(device_count):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        properties = torch.cuda.get_device_properties(i)\n",
        "        print(f\"  CUDA Capability: {properties.major}.{properties.minor}\")\n",
        "        print(f\"  Total memory: {properties.total_memory / (1024**3):.2f} GB\")\n",
        "        print(f\"  Multiprocessors: {properties.multi_processor_count}\")\n",
        "        print(f\"  Max threads per multiprocessor: {properties.max_threads_per_multi_processor}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CUDA devices: 1\n",
            "Device 0: Tesla T4\n",
            "  CUDA Capability: 7.5\n",
            "  Total memory: 14.74 GB\n",
            "  Multiprocessors: 40\n",
            "  Max threads per multiprocessor: 1024\n"
          ]
        }
      ]
    }
  ]
}